import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix
import re

# Load the dataset
data = pd.read_csv('laptop_prices.csv')

# Problem Description
print("\n--- Problem Description ---\n")
print("The objective is to predict laptop prices (regression) and categorize them into price segments (classification).")

# Exploratory Data Analysis (EDA)
print("\n--- Exploratory Data Analysis (EDA) ---\n")
print("Shape of dataset:", data.shape)
print("Data overview:")
print(data.info())
print("\nSummary statistics:")
print(data.describe())

# Check for missing values
print("\nMissing values:")
print(data.isnull().sum())

# Convert categorical features to numerical
categorical_columns = ['Brand', 'Processor', 'GPU', 'Operating System']
for col in categorical_columns:
    data[col] = LabelEncoder().fit_transform(data[col])

# Convert storage to numerical values
data['Storage'] = data['Storage'].str.extract(r'(\d+)').astype(float)

# Convert resolution into width and height
resolutions = data['Resolution'].str.extract(r'(\d+)x(\d+)').astype(float)
data['Resolution_Width'] = resolutions[0]
data['Resolution_Height'] = resolutions[1]
data = data.drop(columns=['Resolution'])

# Visualizations
sns.heatmap(data.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation")
plt.show()

sns.histplot(data['Price ($)'], kde=True, bins=30)
plt.title("Price Distribution")
plt.show()

# Define target variable and features for regression
X = data.drop(['Price ($)'], axis=1)
y_regression = data['Price ($)']

# Define target variable for classification
# Categorizing prices into 3 groups: Low (0), Medium (1), High (2)
price_bins = [0, 1000, 2000, data['Price ($)'].max()]
price_labels = [0, 1, 2]
data['Price Category'] = pd.cut(data['Price ($)'], bins=price_bins, labels=price_labels)
y_classification = data['Price Category']

# Split data into train-test sets
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)
X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_classification, test_size=0.2, random_state=42)

# Standardize features for certain models
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_reg)
X_test_scaled = scaler.transform(X_test_reg)

# Model Training and Evaluation
print("\n--- Model Training and Evaluation ---\n")

# Multi-linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train_reg, y_train_reg)
y_pred_reg = linear_model.predict(X_test_reg)
print("Linear Regression RMSE:", np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)))

# Logistic Regression (for classification)
logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_train_clf, y_train_clf)
y_pred_clf_log = logistic_model.predict(X_test_clf)
print("\nLogistic Regression Classification Report:\n", classification_report(y_test_clf, y_pred_clf_log))

# Decision Tree Classifier
tree_model = DecisionTreeClassifier()
tree_model.fit(X_train_clf, y_train_clf)
y_pred_clf_tree = tree_model.predict(X_test_clf)
print("\nDecision Tree Classification Report:\n", classification_report(y_test_clf, y_pred_clf_tree))

# Support Vector Machine (for classification)
svm_model = SVC()
svm_model.fit(X_train_clf, y_train_clf)
y_pred_clf_svm = svm_model.predict(X_test_clf)
print("\nSVM Classification Report:\n", classification_report(y_test_clf, y_pred_clf_svm))

# Discussion/Conclusion
print("\n--- Discussion/Conclusion ---\n")
print("Linear Regression provides a good baseline for price prediction.")
print("For classification, Decision Tree and SVM show competitive performance, with some trade-offs in accuracy and interpretability.")
